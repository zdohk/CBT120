                MVS TOOLS AND TRICKS OF THE TRADE
                            MAY 2003

                                      Sam Golob
                                      MVS Systems Programmer
                                      P.O. Box 906
                                      Tallman, New York 10982


** This article was not published by Technical Support magazine **

Sam Golob is a Senior Systems Programmer.  He also participates in
library tours and book signings with his wife, author Courtney Taylor.
Sam can be contacted at sbgolob@cbttape.org and/or
sbgolob@attglobal.net.  The Online CBT Tape web site can be reached
at www.cbttape.org .


SHARING TAPE DRIVES

      This month, I'd like to talk about a remarkable product written by
a remarkable software writer.  This product is free for the installing,
but it is professional-grade work, written by a professional who began
his career writing parts of the MVS and CICS systems for IBM, and who
has been in the software writing business for many years since.  I am
sure that this product will be useful for the requirements of many MVS
shops today, which is why I'm writing about it.

      Today's subject is about sharing a pool of tape drives among one
or more MVS systems.  This has perennially been a sore spot in a data
center ever since I can remember, and I've been in this field for a long
time too.  One problem with tape drives, is figuring out how many of
them your shop should have.  Tape drives are expensive to buy and
maintain, so you generally want as few of them as you can get away with
having.  Their usage pattern in most shops is such, that often they are
all idle, and then all of a sudden, you don't have enough of them to go
around.  This problem is made worse when you have a requirement that
multiple MVS systems share the same pool of tape drives.  Ideally, you'd
like your tape workload to be planned so that some of your tape drives
will be busy most of the time, with enough extra drives in reserve to
accommodate the heavy usage times.  And it shouldn't be a problem to
shift this tape workload to another MVS system, any time the shop needs
it.  But practically speaking, that is much easier said than done,
unless you have extra software to serialize and manage the tape drive
usage.

      The advent of "Automated Tape Libraries" and "Virtual Tape
Subsystems" has relieved this requirement somewhat, for shops that are
big enough to afford them.  Automated Tape Libraries are banks of "real
tape drives" that are fitted out with elaborate robotic systems to mount
the tape cartridges automatically, under software control.  Virtual Tape
Subsystems are like automated tape libraries, except that the tape
drives are not real, being simulated by disk files.  Using a Virtual
Tape Subsystem, if you need an actual tape to send out-of-house, there
is provision to copy a "virtual tape" to a real cartridge.  And the
entire inventory can be stacked and backed up on high-capacity tape
cartridges, for disaster recovery purposes.  But even these automated
systems only lessen the tape sharing problems.  They do not eliminate
them.  And they too, are expensive.

      The package I am writing about today, is called TapeMan, and it
is written by Simon Spanchak.  Simon's web site is www.exspans.com.
TapeMan is a sophisticated tape pooling and tape sharing software tool.
In the rest of this column, I'll explain how TapeMan works.  And you can
also use this knowledge to understand the principles behind those
vendor-written software products which do approximately the same thing.


SERIALIZING/SHARING A POOL OF TAPE DRIVES

      Anybody who is familiar with MVS operations will tell you that
when you have several jobs contending for a pool of existing tape
drives, you have to answer a bunch of operator messages.  See Figure 1
for a likely sequence of these messages.  It is true that you can have
your Automated Operations package answer those messages for you, but
most people would prefer to execute their tape jobs in a more orderly
manner.  For example, if a job that needs tapes can't get all the tapes
it needs, many shops would prefer that the job wait until enough
drives are available.  Then the jobs can execute in an orderly fashion.

      Now consider the complications involved when several MVS systems
that are not "sysplexed", are contending for the same pool of tapes.
Many shops get around that, by not allocating the same tape drives to
the different MVS systems.  But often that practice will decrease the
potential efficiency of the shop's tape drive usage.  One system's
workload at a given time might not require tapes at all, while the other
system might demand use of the full tape drive pool for a single job.
Where you aren't sharing the entire pool of drives, queueing theory will
tell you that a large bottleneck can result in your shop's batch window.

      Another problem needs to be mentioned.  If two systems are
sharing one tape drive, you need some form of serialization, because
jobs from both systems might try to write to the same tape at the
same time.  If you want to share a tape drive between two MVS systems,
you have to solve that problem too.

      So this leads us to the idea that if you can share a pool of
tape drives between several MVS systems, but you can also make sure
that there is no concurrent contention for any drive, across all of
the systems, you'll have accomplished quite an efficient use of the
tape drive resource pool.  Simon Spanchak's TapeMan package does
exactly that, so now I'm going to show you how it works.


TAPEMAN BASIC OPERATION

      TapeMan accomplishes its wizardry using four system exits, besides
its own code.  These system exits extract all the tape unit related
information from the system, and allow all the necessary automated and
manual system interventions for TapeMan to do its job.  The exits are:
JES2 Exit 6, JES2 Exit 32, IEFUSI, and IEFACTRT.  I must also mention
that TapeMan, though it does not run as a subsystem itself, employs
subsystem interface calls 9 and 10, so it can intercept console traffic,
such as VARY commands for tape drives.

      Upon initialization, TapeMan finds out all the tape devices
you've got on your system, and checks its startup parameters, to decide
which ones it's going to control.  Then it allocates all these devices
to itself.  TapeMan serializes tape drive usage by controlling all the
tape drives first.

      When jobs come into the system, JES2 Exit 6 (the converter exit)
is activated, and information about the JCL cards is passed to TapeMan.
TapeMan looks at the JCL DD cards (including doing catalog lookups) and
it also gets the device type information from the UNIT keyword values.
Of course, TapeMan is trying to sniff out all possible ways that the
job needs tape drives.  For each job submitted, TapeMan builds a table
entry in its own table.

      Eventually, the job is started, and Exit 32 (job selection time
exit) kicks off.  Exit 32 gets control shortly before the $HASP373
jobname STARTED message gets displayed on the console.  Exit 32 allows
TapeMan to do job-related I/O to its own control block(s), and to alter
console messages related to the job.  Of course these messages will have
to do with tape drives.  When each job starts, TapeMan marks the job in
its own tables, that the job has started.

      When each job step is started, the IEFUSI (step initialization)
exit gets control.  TapeMan looks to see if it has all of the devices
the job step needs.  This has already been determined from TapeMan's
previous processing.  If it has the drives, TapeMan unallocates them
from itself and lets the job start.

      After the job step has been allowed to start, TapeMan itself (in
its own code) checks the JES control block entries for the job, to see
if the job has managed to grab all the tape devices it needs for that
step.  TapeMan then seizes back any other tape devices that the job step
did not need.  TapeMan is also capable of "locking allocation", to make
sure some other job doesn't grab a tape device during the small window
before TapeMan has grabbed all the unused tape drives back to itself.
Obviously, TapeMan has to be an authorized program.

      Then the job runs with the tapes, until the step ends.

      At step end, the IEFACTRT exit (step end, job end exit) receives
control and notifies TapeMan that the step has ended.  TapeMan grabs
back all the tape devices that the job step was using.  So whenever a
job is not using tapes, TapeMan owns those tape drives.


SHARING TAPE DRIVES OVER MULTIPLE SYSTEMS

      TapeMan does not require that multiple MVS systems be sysplexed.
This is a great advantage for shops with configurations that require
separate machines with completely unrelated workloads to share a pool of
tape drives.  Such installations often do not want to go to the effort
of creating a full-blown sysplex with the proper coupling device(s).
All they want to do is to save the expense of maintaining multiple pools
of tape drives for all the different systems.  Here's where TapeMan
helps a lot.  TapeMan will control the one pool of drives over all these
MVS systems.

      GRS can also provide unified multi-system control over one pool
of tape drives, but all those MVS systems have to be fully sysplexed
together, in order for that to work.  TapeMan is much more forgiving.

      Of course, there needs to be a common point of control, where all
the TapeMan images on the different MVS systems can communicate.  In
TapeMan's case, this is simply a shared disk file on a shared disk pack.
That is TapeMan's only requirement for the cross-system communications.
It is self-evident that you need just one more thing.  All the tape
drives in the pool have to be capable of being brought simultaneously
online to all the systems.  So each MVS image has to have a
communication path to each managed drive.

      At this point, I must answer a question you probably have in your
mind.  Suppose a given tape drive has a unit name of say 0596 on one MVS
system, and it has unit name of 0A96 on another system, what do you do?
The answer is that any instance of TapeMan on one MVS system, has
provision in its initialization parameters to define each drive as it
appears to all the other connected MVS systems.  So you set up all the
TapeMan instances on each connected system, to know about each
controlled tape drive as it appears to all the other systems too.
The easiest way this is accomplished, is to give an installation-defined
"share name" to each controlled tape drive in the TapeMan parameters.
Then, each instance of TapeMan will find the drive by its "share name",
rather than by its actual unit address.

      So to control one pool of tape drives over multiple MVS systems,
you need an instance of TapeMan to be running on each of these MVS
systems.

      What does TapeMan do, when a job on another MVS system is using a
tape drive?  It's quite simple.  Before releasing a tape drive, TapeMan
checks the shared file, to see if any other MVS system is currently
using that drive.  If the drive is in use by some other system, our
instance of TapeMan knows that the drive is unavailable to any of the
eligible jobs on its own system, so it won't release it.  Thus we have
effectively and elegantly accomplished the serialization of tape drives
between all of the MVS systems.


ABOUT THE AUTHOR

      Simon Spanchak has been writing MVS system software for over 30
years.  His first job was with IBM itself, in Hursley, where he wrote
components of both MVS and CICS.  This provided Simon with an extremely
solid base of system knowledge, as well as igniting his lifelong passion
for writing system tools and system components.

      During his long employment history, Simon has acquired vast system
knowledge.  But he has especially gravitated to writing "shared systems"
and packages that cooperate one with another.  As with many software
authors, Simon has developed a system of Assembler macros and common
tools (called "SS macros" and "SS server") which allow him to create
"shared" and "cooperative" applications with amazing rapidity.  In fact,
the entire TapeMan package is largely a front-end to Simon's SS Server
package of common routines.

      Simon Spanchak lives in Canada and is available for consulting
work.  His web site is www.exspans.com .  I am very proud to know Simon
personally, and I keep in touch with him on a regular basis.

      I hope that this month's column will provide you with some new
knowledge, or at least some new directions to think about.  Best of luck
to all of you.  I'll see you next month.

  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *  *

Figure 1.   Two Tape Jobs Contend for the Same Tape Drive.
            Here's the reaction of native MVS without TapeMan.

            Job SBGOLOBM needs drive 0560.  Then Job SBGOLOBN is
            submitted, and it also needs drive 0560.  Here is the
            sequence of messages that MVS generates, which must
            be replied to.   When Job SBGOLOBM ends or is
            cancelled, Job SBGOLOBN then pops up and requests its
            tape on drive 0560.


      JOB00304 $HASP373 SBGOLOBM STARTED - INIT 2    - CLASS B - SYS SYS1
      JOB00304 IEF403I SBGOLOBM - STARTED - TIME=18.10.09
      JOB00304*IEF233A M 0560,EXS002,,SBGOLOBM,TAPEMAP,
                       SYS03092.T181009.RA000.SBGOLOBM.R0100022
      JOB00305 $HASP373 SBGOLOBN STARTED - INIT 3    - CLASS B - SYS SYS1
      JOB00305 IEF403I SBGOLOBN - STARTED - TIME=18.10.23
      JOB00305 IEF244I SBGOLOBN TAPEMAP - UNABLE TO ALLOCATE 1 UNIT(S)
                       AT LEAST 1 ALLOCATED UNIT(S) NEEDED.
      JOB00305 IEF488I SBGOLOBN - SYSUT1 MUST WAIT FOR UNIT 0560
      JOB00305 *02 IEF238D SBGOLOBN - REPLY 'WAIT' OR 'CANCEL'.
      2WAIT
      JOB00305 *03 IEF433D SBGOLOBN - WAIT REQUESTED -- REPLY 'HOLD'
     * OR 'NOHOLD'.
      3NOHOLD
      JOB00305  IEE600I REPLY TO 03 IS;NOHOLD
               c sbgolobm
               IEE301I SBGOLOBM          CANCEL COMMAND ACCEPTED
     JOB00304  IEF234E K 0560,EXS002,PVT,SBGOLOBM,TAPEMAP
     JOB00305 *IEF233A M 0560,EXS003,,SBGOLOBN,TAPEMAP,
                       SYS03092.T181023.RA000.SBGOLOBN.R0100023

